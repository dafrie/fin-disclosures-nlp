{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with baseline model (TF-IDF SVM classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import data.dataframe_preparation as preparation\n",
    "from data.labels_postprocessing import process\n",
    "from data.dataframe_preparation import get_counts_per_page, get_keywords_from_file, get_text_from_page, get_count_matrix\n",
    "from data.preprocessing import DocumentPreprocessor\n",
    "from data.inference_widgets import CroInferenceViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIG ###############\n",
    "FIRM_METADATA = os.path.abspath(\"../input_files/Firm_Metadata.csv\")\n",
    "DATA_INPUT_PATH = os.path.abspath(\"../input_files/annual_reports/\")\n",
    "MASTER_DATA_PATH = os.path.abspath(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Data/stoxx_inference/Firm_AnnualReport.csv\")\n",
    "INFERENCE_PARAGRAPH_PATH = os.path.abspath(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Data/stoxx_inference/Firm_AnnualReport_Paragraphs_with_actual_back.pkl\")\n",
    "MODELS_PATH = os.path.abspath(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Models/stoxx_inference\")\n",
    "######################################\n",
    "\n",
    "# Load master file\n",
    "df = pd.read_csv(MASTER_DATA_PATH)\n",
    "df = df.set_index(\"id\")\n",
    "\n",
    "# Load paragraphs file\n",
    "if Path(INFERENCE_PARAGRAPH_PATH).is_file():\n",
    "    df_paragraphs = pd.read_pickle(INFERENCE_PARAGRAPH_PATH)\n",
    "else:\n",
    "    df_paragraphs = pd.DataFrame()\n",
    "\n",
    "# Load classifier\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(MODELS_PATH, 'multilabel_svm_cro.pkl'), 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "label_list = clf.label_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>orig_report_type</th>\n",
       "      <th>report_type</th>\n",
       "      <th>year</th>\n",
       "      <th>input_file</th>\n",
       "      <th>output_file</th>\n",
       "      <th>should_infer</th>\n",
       "      <th>is_inferred</th>\n",
       "      <th>company_id</th>\n",
       "      <th>firm_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>country</th>\n",
       "      <th>icb_industry</th>\n",
       "      <th>icb_supersector</th>\n",
       "      <th>labelling_dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dk_novo_nordisk_b-AR_2016</th>\n",
       "      <td>novo_nordisk_b</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2016</td>\n",
       "      <td>dk_novo_nordisk_b/AR_2016.pdf</td>\n",
       "      <td>AR_2016.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>dk_novo_nordisk_b</td>\n",
       "      <td>NOVO NORDISK B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dk</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dk_novo_nordisk_b-AR_2002</th>\n",
       "      <td>novo_nordisk_b</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2002</td>\n",
       "      <td>dk_novo_nordisk_b/AR_2002.pdf</td>\n",
       "      <td>AR_2002.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>dk_novo_nordisk_b</td>\n",
       "      <td>NOVO NORDISK B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dk</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dk_novo_nordisk_b-AR_2003</th>\n",
       "      <td>novo_nordisk_b</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2003</td>\n",
       "      <td>dk_novo_nordisk_b/AR_2003.pdf</td>\n",
       "      <td>AR_2003.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>dk_novo_nordisk_b</td>\n",
       "      <td>NOVO NORDISK B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dk</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dk_novo_nordisk_b-AR_2017</th>\n",
       "      <td>novo_nordisk_b</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2017</td>\n",
       "      <td>dk_novo_nordisk_b/AR_2017.pdf</td>\n",
       "      <td>AR_2017.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>dk_novo_nordisk_b</td>\n",
       "      <td>NOVO NORDISK B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dk</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dk_novo_nordisk_b-AR_2001</th>\n",
       "      <td>novo_nordisk_b</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2001</td>\n",
       "      <td>dk_novo_nordisk_b/AR_2001.pdf</td>\n",
       "      <td>AR_2001.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>dk_novo_nordisk_b</td>\n",
       "      <td>NOVO NORDISK B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dk</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch_novartis-AR_2012</th>\n",
       "      <td>novartis</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2012</td>\n",
       "      <td>ch_novartis/AR_2012.pdf</td>\n",
       "      <td>AR_2012.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ch_novartis</td>\n",
       "      <td>NOVARTIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch_novartis-AR_2008</th>\n",
       "      <td>novartis</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2008</td>\n",
       "      <td>ch_novartis/AR_2008.pdf</td>\n",
       "      <td>AR_2008.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ch_novartis</td>\n",
       "      <td>NOVARTIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch_novartis-AR_2009</th>\n",
       "      <td>novartis</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2009</td>\n",
       "      <td>ch_novartis/AR_2009.pdf</td>\n",
       "      <td>AR_2009.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ch_novartis</td>\n",
       "      <td>NOVARTIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch_novartis-AR_2019</th>\n",
       "      <td>novartis</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2019</td>\n",
       "      <td>ch_novartis/AR_2019.pdf</td>\n",
       "      <td>AR_2019.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ch_novartis</td>\n",
       "      <td>NOVARTIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch_novartis-AR_2018</th>\n",
       "      <td>novartis</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>2018</td>\n",
       "      <td>ch_novartis/AR_2018.pdf</td>\n",
       "      <td>AR_2018.yml</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ch_novartis</td>\n",
       "      <td>NOVARTIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch</td>\n",
       "      <td>20 Health Care</td>\n",
       "      <td>2010 Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  company orig_report_type report_type  year  \\\n",
       "id                                                                             \n",
       "dk_novo_nordisk_b-AR_2016  novo_nordisk_b               AR          AR  2016   \n",
       "dk_novo_nordisk_b-AR_2002  novo_nordisk_b               AR          AR  2002   \n",
       "dk_novo_nordisk_b-AR_2003  novo_nordisk_b               AR          AR  2003   \n",
       "dk_novo_nordisk_b-AR_2017  novo_nordisk_b               AR          AR  2017   \n",
       "dk_novo_nordisk_b-AR_2001  novo_nordisk_b               AR          AR  2001   \n",
       "...                                   ...              ...         ...   ...   \n",
       "ch_novartis-AR_2012              novartis               AR          AR  2012   \n",
       "ch_novartis-AR_2008              novartis               AR          AR  2008   \n",
       "ch_novartis-AR_2009              novartis               AR          AR  2009   \n",
       "ch_novartis-AR_2019              novartis               AR          AR  2019   \n",
       "ch_novartis-AR_2018              novartis               AR          AR  2018   \n",
       "\n",
       "                                              input_file  output_file  \\\n",
       "id                                                                      \n",
       "dk_novo_nordisk_b-AR_2016  dk_novo_nordisk_b/AR_2016.pdf  AR_2016.yml   \n",
       "dk_novo_nordisk_b-AR_2002  dk_novo_nordisk_b/AR_2002.pdf  AR_2002.yml   \n",
       "dk_novo_nordisk_b-AR_2003  dk_novo_nordisk_b/AR_2003.pdf  AR_2003.yml   \n",
       "dk_novo_nordisk_b-AR_2017  dk_novo_nordisk_b/AR_2017.pdf  AR_2017.yml   \n",
       "dk_novo_nordisk_b-AR_2001  dk_novo_nordisk_b/AR_2001.pdf  AR_2001.yml   \n",
       "...                                                  ...          ...   \n",
       "ch_novartis-AR_2012              ch_novartis/AR_2012.pdf  AR_2012.yml   \n",
       "ch_novartis-AR_2008              ch_novartis/AR_2008.pdf  AR_2008.yml   \n",
       "ch_novartis-AR_2009              ch_novartis/AR_2009.pdf  AR_2009.yml   \n",
       "ch_novartis-AR_2019              ch_novartis/AR_2019.pdf  AR_2019.yml   \n",
       "ch_novartis-AR_2018              ch_novartis/AR_2018.pdf  AR_2018.yml   \n",
       "\n",
       "                           should_infer  is_inferred         company_id  \\\n",
       "id                                                                        \n",
       "dk_novo_nordisk_b-AR_2016          True         True  dk_novo_nordisk_b   \n",
       "dk_novo_nordisk_b-AR_2002          True         True  dk_novo_nordisk_b   \n",
       "dk_novo_nordisk_b-AR_2003          True         True  dk_novo_nordisk_b   \n",
       "dk_novo_nordisk_b-AR_2017          True         True  dk_novo_nordisk_b   \n",
       "dk_novo_nordisk_b-AR_2001          True         True  dk_novo_nordisk_b   \n",
       "...                                 ...          ...                ...   \n",
       "ch_novartis-AR_2012                True         True        ch_novartis   \n",
       "ch_novartis-AR_2008                True         True        ch_novartis   \n",
       "ch_novartis-AR_2009                True         True        ch_novartis   \n",
       "ch_novartis-AR_2019                True         True        ch_novartis   \n",
       "ch_novartis-AR_2018                True         True        ch_novartis   \n",
       "\n",
       "                                firm_name  ticker country    icb_industry  \\\n",
       "id                                                                          \n",
       "dk_novo_nordisk_b-AR_2016  NOVO NORDISK B     NaN      dk  20 Health Care   \n",
       "dk_novo_nordisk_b-AR_2002  NOVO NORDISK B     NaN      dk  20 Health Care   \n",
       "dk_novo_nordisk_b-AR_2003  NOVO NORDISK B     NaN      dk  20 Health Care   \n",
       "dk_novo_nordisk_b-AR_2017  NOVO NORDISK B     NaN      dk  20 Health Care   \n",
       "dk_novo_nordisk_b-AR_2001  NOVO NORDISK B     NaN      dk  20 Health Care   \n",
       "...                                   ...     ...     ...             ...   \n",
       "ch_novartis-AR_2012              NOVARTIS     NaN      ch  20 Health Care   \n",
       "ch_novartis-AR_2008              NOVARTIS     NaN      ch  20 Health Care   \n",
       "ch_novartis-AR_2009              NOVARTIS     NaN      ch  20 Health Care   \n",
       "ch_novartis-AR_2019              NOVARTIS     NaN      ch  20 Health Care   \n",
       "ch_novartis-AR_2018              NOVARTIS     NaN      ch  20 Health Care   \n",
       "\n",
       "                            icb_supersector labelling_dataset  \n",
       "id                                                             \n",
       "dk_novo_nordisk_b-AR_2016  2010 Health Care               NaN  \n",
       "dk_novo_nordisk_b-AR_2002  2010 Health Care               NaN  \n",
       "dk_novo_nordisk_b-AR_2003  2010 Health Care               NaN  \n",
       "dk_novo_nordisk_b-AR_2017  2010 Health Care               NaN  \n",
       "dk_novo_nordisk_b-AR_2001  2010 Health Care               NaN  \n",
       "...                                     ...               ...  \n",
       "ch_novartis-AR_2012        2010 Health Care               NaN  \n",
       "ch_novartis-AR_2008        2010 Health Care          training  \n",
       "ch_novartis-AR_2009        2010 Health Care               NaN  \n",
       "ch_novartis-AR_2019        2010 Health Care               NaN  \n",
       "ch_novartis-AR_2018        2010 Health Care               NaN  \n",
       "\n",
       "[792 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get paragraphs of all reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_keywords_from_file(\"../data/keyword_vocabulary.txt\")\n",
    "\n",
    "def get_paragraphs_of_report(report_row, add_adjunct_pages=True):\n",
    "    result = []\n",
    "    \n",
    "    # Load report\n",
    "    path = os.path.join(DATA_INPUT_PATH,report_row['input_file'])\n",
    "    folder = os.path.dirname(path)\n",
    "    parsed_report_file_path = os.path.join(folder, report_row['orig_report_type'] + '_' + str(int(report_row['year'])), report_row['output_file'])\n",
    "    \n",
    "    # Get pages with keyword hits\n",
    "    pages = get_counts_per_page(parsed_report_file_path, vocabulary)\n",
    "    page_indizes = set(pages.index)\n",
    "    \n",
    "    # Add adjunct pages if necessary\n",
    "    if add_adjunct_pages:\n",
    "        for p in pages.index:\n",
    "            if p > 0:\n",
    "                page_indizes.add(p - 1)\n",
    "            # elif p < TOTAL_PAGES:\n",
    "            page_indizes.add(p + 1)\n",
    "            \n",
    "    # For each page, get all paragraphs\n",
    "    for page_no in page_indizes:\n",
    "        try:\n",
    "            text = get_text_from_page(parsed_report_file_path, page_no)\n",
    "            processed_doc = DocumentPreprocessor(text).process()\n",
    "        except IndexError:\n",
    "            continue\n",
    "        paragraphs = processed_doc.split('\\n\\n')\n",
    "        \n",
    "        for idx, p in enumerate(paragraphs):\n",
    "            result.append({ \"page_no\": page_no, \"paragraph_no\": idx, \"text\": p, \"is_adjunct\": False if page_no in pages.index else True })\n",
    "        print(f\"Page no: {page_no}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "from tqdm.notebook import trange, tqdm_notebook\n",
    "\n",
    "# Loop through all reports\n",
    "for index, row in tqdm_notebook(df.iterrows(), total=df.shape[0]):\n",
    "    # Skip if not necessary\n",
    "    if not row['should_infer'] or row['is_inferred']:\n",
    "        continue\n",
    "        \n",
    "    paragraphs = get_paragraphs_of_report(row, add_adjunct_pages=True)\n",
    "    if len(paragraphs):\n",
    "        df_report_paragraphs = pd.DataFrame(paragraphs)\n",
    "\n",
    "        paragraphs_df[\"report_id\"] = index\n",
    "        df_paragraphs = pd.concat([df_paragraphs, df_report_paragraphs], ignore_index=True)\n",
    "    \n",
    "    # Update progress\n",
    "    df.loc[index, 'is_inferred'] = True\n",
    "    \n",
    "    # Save files\n",
    "    df.to_csv(MASTER_DATA_PATH)\n",
    "    df_paragraphs.to_pickle(INFERENCE_PARAGRAPH_PATH, protocol=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add inference step here instead of above, i.e. it make dynamic\n",
    "df_paragraphs[\"preds_svm_cro\"] = clf.predict(df_paragraphs['text']).tolist()\n",
    "df_paragraphs[\"preds_prob_svm_cro\"] = clf.predict_proba(df_paragraphs['text']).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data/extract prob\n",
    "df_paragraphs[[ l + \"_predicted\" for l in label_list]] = pd.DataFrame(df_paragraphs.preds_svm_cro.tolist())\n",
    "df_paragraphs[[ l + \"_prob\" for l in label_list]] = pd.DataFrame(df_paragraphs.preds_prob_svm_cro.tolist())\n",
    "\n",
    "# Merge dataset\n",
    "df_paragraphs_merged = pd.merge(df_paragraphs, df, how=\"left\", left_on=\"report_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs.groupby(\"labelling_dataset\", dropna=False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary: Combine from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun once test is complete\n",
    "df_labels_training = pd.read_pickle(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Labelling/annual reports/Firm_AnnualReport_Labels_Training_Positive.pkl\")\n",
    "df_labels_training_negative = pd.read_pickle(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Labelling/annual reports/Firm_AnnualReport_Labels_Training_Negative.pkl\")\n",
    "df_labels_test = pd.read_pickle(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Labelling/annual reports/Firm_AnnualReport_Labels_Test_Positive.pkl\")\n",
    "\n",
    "# Set ids\n",
    "id_columns = ['report_id', 'page', 'paragraph_no']\n",
    "df_labels_training[\"id\"] = df_labels_training.apply(lambda row: \"_\".join([str(row[c]) for c in id_columns]), axis=1)\n",
    "df_labels_training_negative[\"id\"] = df_labels_training_negative.apply(lambda row: \"_\".join([str(row[c]) for c in id_columns]), axis=1)\n",
    "df_labels_test[\"id\"] = df_labels_test.apply(lambda row: \"_\".join([str(row[c]) for c in id_columns]), axis=1)\n",
    "\n",
    "# Quick check that we do not have overlapping labels\n",
    "assert len(set(df_labels_training.id).intersection(set(df_labels_training_negative.id))) == 0\n",
    "assert len(set(df_labels_training.id).intersection(set(df_labels_test.id))) == 0\n",
    "\n",
    "df_labels = pd.concat([df_labels_training, df_labels_test])\n",
    "df_cro = pd.crosstab(df_labels.id, df_labels[\"cro\"], dropna=False)\n",
    "df_cro_sub_type = pd.crosstab(df_labels.id, df_labels[\"cro_sub_type_combined\"], dropna=False)\n",
    "df_cro = df_cro.add_suffix('_actual')\n",
    "df_cro_sub_type = df_cro_sub_type.add_suffix('_actual')\n",
    "df_cro = (df_cro > 0) * 1\n",
    "df_cro_sub_type = (df_cro_sub_type > 0) * 1\n",
    "\n",
    "id_columns = ['report_id', 'page_no', 'paragraph_no']\n",
    "assert len(df_paragraphs_merged) == len(df_paragraphs_merged.groupby(id_columns).count()), \"Should only have unique id's, something is not correct!\"\n",
    "\n",
    "id_columns = ['report_id', 'page_no', 'paragraph_no']\n",
    "df_paragraphs_merged[\"id\"] = df_paragraphs_merged.apply(lambda row: \"_\".join([str(row[c]) for c in id_columns]), axis=1)\n",
    "\n",
    "df_paragraphs_merged = df_paragraphs_merged.merge(df_cro, how=\"left\", left_on=\"id\", right_index=True)\n",
    "df_paragraphs_merged = df_paragraphs_merged.merge(df_cro_sub_type, how=\"left\", left_on=\"id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs_merged.to_pickle(\"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Data/stoxx_inference/Firm_AnnualReport_Paragraphs_with_actual.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa23d8726a19499788a408278bde3b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02b5d4532f645558065c1da738fa767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2546e47c70a54d3fa4708a7c346f5a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.inference_widgets import CroInferenceViewer\n",
    "df_paragraphs_merged = df_paragraphs\n",
    "viewer = CroInferenceViewer(df_paragraphs_merged, label_list=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs_merged.columns # cro_sub_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_paragraphs_merged.iloc[549581])\n",
    "print(df_paragraphs_merged.iloc[549581].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs_merged.query(\"REPUTATION_actual == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
