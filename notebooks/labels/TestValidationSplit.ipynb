{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/validation stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/v2/labelling/\"\n",
    "CRO_LEVEL = \"cro_sub_type\" # cro, cro_sub_type\n",
    "CATEGORY_CODES = [\"ACUTE\", \"CHRON\", \"POLICY\", \"MARKET\", \"REPUT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing \"cleaned\" positives (and resulting good negatives!)\n",
    "df1 = pd.read_excel(os.path.join(DATA_DIR, \"old_train_positives_BS_v02.xls\"))\n",
    "df1 = df1.set_index(\"id\")\n",
    "df1 = df1.rename(columns={\"REPUTATION\": \"REPUT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, we only want to get the additional negatives\n",
    "df2 = pd.read_pickle(os.path.join(DATA_DIR, \"Firm_AnnualReport_Labels_Training_Negative_incl_adjunct.pkl\"))\n",
    "df2[\"id\"] = df2.apply(lambda row: f\"{row.report_id}_{str(row.page)}_{str(row.paragraph_no)}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, we only want to get the additional negatives\n",
    "df2 = pd.read_pickle(os.path.join(DATA_DIR, \"Firm_AnnualReport_Labels_Training_Negative_incl_adjunct.pkl\"))\n",
    "df2[\"id\"] = df2.apply(lambda row: f\"{row.report_id}_{str(row.page)}_{str(row.paragraph_no)}\", axis=1)\n",
    "\n",
    "df2 = pd.DataFrame({ \"text\": df2.groupby([\"id\"]).first().text })\n",
    "df2[CATEGORY_CODES] = 0\n",
    "\n",
    "# TODO: Not used?\n",
    "missing_idx = df2.index.difference(df1.index)\n",
    "df_combined = df1.append(df2.loc[missing_idx, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing \"cleaned\" positives (and resulting good negatives!)\n",
    "df3 = pd.read_excel(os.path.join(DATA_DIR, \"old_test_positives_DF.xls\"))\n",
    "df3 = df3.rename(columns={\"REPUTATION\": \"REPUT\", \"Unnamed: 0\": \"id\"})\n",
    "df3 = df3.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, we only want to get the additional negatives\n",
    "df4 = pd.read_pickle(os.path.join(DATA_DIR, \"Firm_AnnualReport_Labels_Test.pkl\"))\n",
    "df4[\"id\"] = df4.apply(lambda row: f\"{row.report_id}_{str(row.page)}_{str(row.paragraph_no)}\", axis=1)\n",
    "\n",
    "df4_docs = df4.groupby([\"id\"]).first().text\n",
    "df4[\"cro_sub_type_combined\"].loc[df4[\"cro_sub_type_combined\"] != df4[\"cro_sub_type_combined\"]] = \"missing\"\n",
    "df4_labels = pd.crosstab(df4.id, df4[\"cro_sub_type_combined\"], dropna=False)\n",
    "df4_labels = df4_labels.rename(columns={\"REPUTATION\": \"REPUT\"})\n",
    "df4_labels = df4_labels[CATEGORY_CODES]\n",
    "\n",
    "missing_idx_test = df4_labels.index.difference(df3.index)\n",
    "df4 = df4_labels.join(df4_docs)\n",
    "df4 = df4.loc[missing_idx_test, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split stratified groups of company reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_company(df):\n",
    "    df[\"company\"] = df.apply(lambda row: row.name.split(\"-\")[0], axis=1)\n",
    "    return df\n",
    "\n",
    "df1 = add_company(df1)\n",
    "df2 = add_company(df2)\n",
    "df3 = add_company(df3)\n",
    "df4 = add_company(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_explicit = df1.append(df3)\n",
    "all_negative = df2.append(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = all_negative.company.unique()\n",
    "from sklearn.model_selection import train_test_split\n",
    "valid_companies, test_companies = train_test_split(all_companies.tolist(), test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_all_explicit = all_explicit.query(\"company in @valid_companies\")\n",
    "test_all_explicit = all_explicit.query(\"company in @test_companies\")\n",
    "\n",
    "valid_all_negative = all_negative.query(\"company in @valid_companies\")\n",
    "test_all_negative = all_negative.query(\"company in @test_companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_realistic = valid_all_explicit.append(valid_all_negative)\n",
    "test_realistic = test_all_explicit.append(test_all_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label_file(df, path):\n",
    "    # Remove shit\n",
    "    columns = CATEGORY_CODES + [\"text\"]\n",
    "    df = df[columns]\n",
    "    df.to_csv(path)\n",
    "    \n",
    "save_label_file(valid_all_explicit, os.path.join(DATA_DIR, \"valid_optimistic.csv\"))\n",
    "save_label_file(test_all_explicit, os.path.join(DATA_DIR, \"test_optimistic.csv\"))\n",
    "save_label_file(valid_realistic, os.path.join(DATA_DIR, \"valid_realistic.csv\"))\n",
    "save_label_file(test_realistic, os.path.join(DATA_DIR, \"test_realistic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pos_only = valid_all_explicit[valid_all_explicit[CATEGORY_CODES].any(axis='columns')]\n",
    "test_pos_only = test_all_explicit[test_all_explicit[CATEGORY_CODES].any(axis='columns')]\n",
    "\n",
    "save_label_file(valid_pos_only, os.path.join(DATA_DIR, \"valid_discriminatory.csv\"))\n",
    "save_label_file(test_pos_only, os.path.join(DATA_DIR, \"test_discriminatory.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train_explicit.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \n",
      "ACUTE     133\n",
      "CHRON      54\n",
      "POLICY     43\n",
      "MARKET     37\n",
      "REPUT      23\n",
      "dtype: int64\n",
      "Unique rows: 205\n",
      "All Negatives: 295\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: \\n{train_df[CATEGORY_CODES].sum()}\")\n",
    "unique_pos_rows = train_df[CATEGORY_CODES].any(axis='columns').sum()\n",
    "print(f\"Unique rows: {unique_pos_rows}\")\n",
    "print(f\"All Negatives: {len(train_df) - unique_pos_rows}\")\n",
    "#print(f\"Explicit neg: {len(df2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: \n",
      "ACUTE     15\n",
      "CHRON      5\n",
      "POLICY    40\n",
      "MARKET    17\n",
      "REPUT     14\n",
      "dtype: int64\n",
      "Unique rows: 72\n",
      "All Negatives: 39007\n",
      "Explicit neg: 73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid: \\n{valid_realistic[CATEGORY_CODES].sum()}\")\n",
    "unique_pos_rows = valid_realistic[CATEGORY_CODES].any(axis='columns').sum()\n",
    "print(f\"Unique rows: {unique_pos_rows}\")\n",
    "print(f\"All Negatives: {len(valid_realistic) - unique_pos_rows}\")\n",
    "print(f\"Explicit neg: {len(valid_all_explicit) - unique_pos_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "ACUTE     28\n",
      "CHRON     19\n",
      "POLICY    60\n",
      "MARKET    21\n",
      "REPUT     14\n",
      "dtype: int64\n",
      "Unique rows: 97\n",
      "All Negatives: 40878\n",
      "Explicit neg: 55\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test: \\n{test_realistic[CATEGORY_CODES].sum()}\")\n",
    "unique_pos_rows = test_realistic[CATEGORY_CODES].any(axis='columns').sum()\n",
    "print(f\"Unique rows: {unique_pos_rows}\")\n",
    "print(f\"All Negatives: {len(test_realistic) - unique_pos_rows}\")\n",
    "print(f\"Explicit neg: {len(test_all_explicit) - unique_pos_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_pickle(os.path.join(DATA_DIR, \"Firm_AnnualReport_Labels_Test.pkl\"))\n",
    "df4[\"id\"] = df4.apply(lambda row: f\"{row.report_id}_{str(row.page)}_{str(row.paragraph_no)}\", axis=1)\n",
    "\n",
    "df4_docs = df4.groupby([\"id\"]).first().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
