{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dafrie/fin-disclosures-nlp/blob/master/notebooks/CRO_Classification_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs0erh0Fhkas"
   },
   "source": [
    "# Baseline models for CRO Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBQYJovOhphA"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lodc5k4Qhq_A",
    "outputId": "6debe614-3b6f-451c-890e-6d2f998b8560"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  is_running_in_colab = True\n",
    "except:\n",
    "  is_running_in_colab = False\n",
    "\n",
    "if is_running_in_colab:\n",
    "  # Load Google drive where the data and models are stored\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lOuFBCshh0cJ"
   },
   "outputs": [],
   "source": [
    "############################## CONFIG ##############################\n",
    "# Task config\n",
    "TASK = \"multi-label\" #@param [\"multi-label\", \"binary\"]\n",
    "CATEGORY_LEVEL = 'cro' #@param [\"cro\", \"cro_sub_type_combined\"]\n",
    "MODEL_TYPE = \"baseline\" #@param [\"baseline\", \"transformer\"]\n",
    "MODEL_NAME = \"svm\"\n",
    "\n",
    "# Dataset config\n",
    "FILTER_OP = True #@param { type: \"boolean\"}\n",
    "SCENARIO = \"optimistic\" #@param [ \"optimistic\", \"efficient-realistic\", \"realistic\"]\n",
    "\n",
    "# Evaluation metric config. See for context: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "AVERAGING_STRATEGY = 'macro' #@param [\"micro\",  \"macro\", \"weighted\"]\n",
    "\n",
    "RESULTS_FILE_NAME = f\"{CATEGORY_LEVEL}_{TASK}_results.csv\"\n",
    "\n",
    "# To make the notebook reproducible (not guaranteed for pytorch on different releases/platforms!)\n",
    "SEED_VALUE = 42\n",
    "\n",
    "##################\n",
    "\n",
    "# AP is equal to Precision/Recall AUC! See for discussion: https://github.com/scikit-learn/scikit-learn/issues/5992\n",
    "SCORING_METRIC = 'average_precision' #@param [\"average_precision\",  \"roc_auc\"]\n",
    "\n",
    "####################################################################\n",
    "LOCAL_DIR = \"/Users/david/Nextcloud/Dokumente/Education/Uni Bern/Master Thesis/Analyzing Financial Climate Disclosures with NLP/Methodology/\"\n",
    "COLAB_DIR = \"/content/drive/MyDrive/fin-disclosures-nlp\"\n",
    "\n",
    "if SCENARIO == \"optimistic\":\n",
    "  TRAIN_NEG_SAMPLING_STRATEGY = \"None\"\n",
    "  TEST_NEG_SAMPLING_STRATEGY = \"None\"\n",
    "\n",
    "elif SCENARIO == \"efficient-realistic\":\n",
    "  TRAIN_NEG_SAMPLING_STRATEGY = \"only_OP\"\n",
    "  TEST_NEG_SAMPLING_STRATEGY = \"all\"\n",
    "\n",
    "elif SCENARIO == \"realistic\":\n",
    "  TRAIN_NEG_SAMPLING_STRATEGY = \"all\"\n",
    "  TEST_NEG_SAMPLING_STRATEGY = \"all\"\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"task\": TASK,\n",
    "    \"category_level\": CATEGORY_LEVEL,\n",
    "    \"model_type\": MODEL_TYPE,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"scenario\": SCENARIO,\n",
    "    \"seed_value\": SEED_VALUE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZNaOP8Bh5Ss",
    "outputId": "9e4a7022-dbcb-4f9a-ad79-234eab3881d7"
   },
   "outputs": [],
   "source": [
    "if is_running_in_colab:\n",
    "  # Install transformers library + datasets helper\n",
    "  !pip install transformers --quiet\n",
    "  !pip install datasets --quiet\n",
    "  !pip install optuna --quiet\n",
    "  !python -m spacy download en_core_web_md\n",
    "\n",
    "  # Latex for output\n",
    "  ! apt install texlive-latex-recommended -qq\n",
    "  ! apt install texlive-latex-extra -qq\n",
    "  ! apt install dvipng -qq\n",
    "  ! apt install cm-super -qq\n",
    "\n",
    "  # Load repository\n",
    "\n",
    "  !git clone https://github.com/dafrie/fin-disclosures-nlp.git    \n",
    "  %cd /content/fin-disclosures-nlp\n",
    "  !git pull\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('..')\n",
    "\n",
    "if is_running_in_colab:\n",
    "  sys.path.append('.')\n",
    "\n",
    "from data import constants\n",
    "from data import cro_dataset\n",
    "# This module depends on spacy's language models, need to restart the runtime to reload once downloaded.\n",
    "try:\n",
    "  from data import dataframe_preparation\n",
    "except OSError:\n",
    "  exit()\n",
    "from data import dataframe_preparation\n",
    "from data import evaluation\n",
    "\n",
    "DIR = COLAB_DIR if is_running_in_colab else LOCAL_DIR\n",
    "DATA_DIR = os.path.join(DIR, \"data\", \"labels\")\n",
    "MODELS_DIR = os.path.join(DIR, \"models\", MODEL_TYPE)\n",
    "RESULTS_DIR = os.path.join(DIR, 'results')\n",
    "RESULTS_FILE_PATH = os.path.join(RESULTS_DIR, RESULTS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yCNnpmqbh74I"
   },
   "outputs": [],
   "source": [
    "# Load/Initialize results file\n",
    "results = evaluation.Results(RESULTS_FILE_PATH, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1Wi6Gw6iSin",
    "outputId": "25017e4a-e088-4a83-8308-951c37a5bc68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset. Train: 27811, Test: 28209, Dim: 2\n"
     ]
    }
   ],
   "source": [
    "train_docs, train_doc_labels, test_docs, test_doc_labels = cro_dataset.prepare_datasets(\n",
    "    data_dir=DATA_DIR,\n",
    "    task=TASK, \n",
    "    cro_category_level=CATEGORY_LEVEL, \n",
    "    should_filter_op=FILTER_OP, \n",
    "    train_neg_sampling_strategy=TRAIN_NEG_SAMPLING_STRATEGY, \n",
    "    test_neg_sampling_strategy=TEST_NEG_SAMPLING_STRATEGY, \n",
    "    seed_value=SEED_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cro</th>\n",
       "      <th>PR</th>\n",
       "      <th>TR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gb_british_american_tobacco-AR_2010_48_14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_schneider_electric-AR_2012_214_18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_air_liquide-AR_2013_28_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb_hsbc-AR_2006_139_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de_bayer-AR_2016_330_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb_glencore_plc-AR_2014_28_20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de_bayer-AR_2016_128_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch_roche-AR_2014_171_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_loreal-AR_2011_197_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb_national_grid-AR_2008_25_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "cro                                        PR  TR\n",
       "id                                               \n",
       "gb_british_american_tobacco-AR_2010_48_14   0   0\n",
       "fr_schneider_electric-AR_2012_214_18        0   0\n",
       "fr_air_liquide-AR_2013_28_4                 0   0\n",
       "gb_hsbc-AR_2006_139_13                      0   0\n",
       "de_bayer-AR_2016_330_3                      0   0\n",
       "...                                        ..  ..\n",
       "gb_glencore_plc-AR_2014_28_20               0   0\n",
       "de_bayer-AR_2016_128_7                      0   0\n",
       "ch_roche-AR_2014_171_4                      0   0\n",
       "fr_loreal-AR_2011_197_8                     0   0\n",
       "gb_national_grid-AR_2008_25_15              0   0\n",
       "\n",
       "[27811 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUKLUrrdifvb",
    "outputId": "cdd30667-c755-41e1-bf7f-dc512975fe1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('bow',\n",
       "                                        CountVectorizer(strip_accents='ascii')),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('classifier',\n",
       "                                        OneVsRestClassifier(estimator=SVC(class_weight='balanced',\n",
       "                                                                          probability=True,\n",
       "                                                                          random_state=42)))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'bow__ngram_range': [(1, 2)],\n",
       "                          'bow__stop_words': ['english'],\n",
       "                          'bow__tokenizer': [<function spacy_tokenizer at 0x7f8c4e926160>],\n",
       "                          'classifier__estimator__C': [100],\n",
       "                          'classifier__estimator__kernel': ['rbf'],\n",
       "                          'tfidf__use_idf': [True]}],\n",
       "             scoring=make_scorer(average_precision_score, average=macro))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, average_precision_score, roc_auc_score\n",
    "\n",
    "# Custom scorer so we can pass in the averaging strategy\n",
    "avg_scorer = make_scorer(average_precision_score if SCORING_METRIC == 'average_precision' else roc_auc_score, average=AVERAGING_STRATEGY)\n",
    "\n",
    "svc_clf = SVC(probability=True, random_state=SEED_VALUE, class_weight=\"balanced\") # Balanced: n_samples / (n_classes * np.bincount(y)). Since we are doing OneVsRest, this should be giving correct weights!\n",
    "# Wrap with OvR in case of multi-label\n",
    "multi_label_clf = OneVsRestClassifier(svc_clf)\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer(strip_accents = 'ascii')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', multi_label_clf if TASK == \"multi-label\" else svc_clf),\n",
    "     ])\n",
    "\n",
    "# Parameters to tune automatically with a grid search\n",
    "# Note: The nested estimator is accessible via the __estimator identifier\n",
    "param_svm = [\n",
    "  {\n",
    "      'bow__tokenizer': [dataframe_preparation.spacy_tokenizer],\n",
    "      'bow__stop_words': ['english'],\n",
    "      #'bow__ngram_range': [(1, 1), (1, 2)],\n",
    "      'bow__ngram_range': [(1, 2)],\n",
    "      #'bow__max_features': [50],\n",
    "      'tfidf__use_idf': [True], \n",
    "      #'classifier__estimator__C' if TASK == \"multi-label\" else 'classifier__C': [1, 10, 100], \n",
    "      'classifier__estimator__C' if TASK == \"multi-label\" else 'classifier__C': [100], \n",
    "      #'classifier__estimator__kernel' if TASK == \"multi-label\" else 'classifier__kernel': ['linear', 'rbf']},\n",
    "      'classifier__estimator__kernel' if TASK == \"multi-label\" else 'classifier__kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "grid_clf = GridSearchCV(\n",
    "    pipeline_svm,\n",
    "    param_grid=param_svm,\n",
    "    refit=True,\n",
    "    n_jobs=-1, \n",
    "    scoring=avg_scorer,\n",
    ")\n",
    "\n",
    "# Grid search fitting\n",
    "grid_clf.fit(train_docs, train_doc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9fU9PWsii03",
    "outputId": "8c7ac69e-82d4-4fce-a7e3-8d472c4b2b42"
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_clf.cv_results_)\n",
    "\n",
    "print(f\"Best {SCORING_METRIC} score: {grid_clf.best_score_}\")\n",
    "print(f\"Best params: \\n{grid_clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "v730WuEBik9n"
   },
   "outputs": [],
   "source": [
    "# train_preds = grid_clf.predict(train_docs)\n",
    "train_preds_prob = grid_clf.predict_proba(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "jdmCrftMindM",
    "outputId": "543efe0b-0e35-4d52-f968-83713b19853e"
   },
   "outputs": [],
   "source": [
    "train_threshold_moving_report = os.path.join(RESULTS_DIR, \"figures\", f\"{CATEGORY_LEVEL}_{TASK}_{SCENARIO}_{MODEL_NAME}_train_threshold.pdf\")\n",
    "train_eval_scores, best_roc_threshold, best_pr_threshold = evaluation.threshold_moving_report(train_doc_labels, train_preds_prob, export_path=train_threshold_moving_report)\n",
    "results.log_experiment(train_eval_scores, prefix=\"train\")\n",
    "results.log_experiment({ \"best_pr_threshold\": best_pr_threshold.values(), \"best_roc_threshold\": best_roc_threshold.values()}, prefix=\"train\")\n",
    "train_eval_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9P14YLfir8o"
   },
   "source": [
    "# Evaluation on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UW3lr5xipnB"
   },
   "outputs": [],
   "source": [
    "# Predict for test\n",
    "test_preds_prob = grid_clf.predict_proba(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "nfnf8iO8ivcO",
    "outputId": "333169b5-4f0a-451a-b072-4c5cb29269fe"
   },
   "outputs": [],
   "source": [
    "test_eval_report = os.path.join(RESULTS_DIR, 'figures', f\"{CATEGORY_LEVEL}_{TASK}_{SCENARIO}_{MODEL_NAME}_test_report.pdf\")\n",
    "test_eval_scores = evaluation.test_evaluation_report(test_doc_labels, test_preds_prob, best_pr_threshold.values(), averaging=AVERAGING_STRATEGY, export_path=test_eval_report)\n",
    "results.log_experiment(test_eval_scores, prefix=\"test\")\n",
    "test_eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr0dVEENiyAj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "SAVE_MODEL = False\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    with open(os.path.join(MODELS_DIR), f\" {TASK}_svm_{CATEGORY_LEVEL}.pkl\", 'wb') as f:\n",
    "        grid_clf.label_list = label_list\n",
    "        pickle.dump(grid_clf, f, 4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3tMfR8EgclFW7wUqmZefQ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CRO Classification Baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
