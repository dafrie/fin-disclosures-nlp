{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRO - Multi-Class with Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOR7+L4DyKpOff73wIYM1jG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dafrie/fin-disclosures-nlp/blob/master/notebooks/CRO_Multi_Class_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4bR9kFMZ0ZF"
      },
      "source": [
        "# Multi-Class classification of Climate-related risks and opportunities using Transformers\n",
        "Multi-Class = Each document is assigned one of a set of classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQBJKVg0aPnV"
      },
      "source": [
        "# Setup\n",
        "\n",
        "1. Make sure to enable a GPU in Colab by enabling Hardware accelerator support in \"Runtime / Change runtime type\" and then select \"GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P25EXc8YaRYE",
        "outputId": "f575e936-2b34-4614-f392-23f86524ae2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install transformers library\n",
        "!pip install transformers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import textwrap\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "############################## CONFIG ##############################\n",
        "# On which CRO categorization level the \n",
        "CATEGORY_LEVEL = 'cro' #@param [\"cro\", \"cro_sub_type_combined\", \"cro_merge\"]\n",
        "\n",
        "# Set to true if fine-tuning should be enabled. Else it loads fine-tuned model\n",
        "ENABLE_FINE_TUNING = False #@param {type:\"boolean\"}\n",
        "\n",
        "# See list here: https://huggingface.co/models\n",
        "TRANSFORMER_MODEL_NAME = 'bert-base-uncased' #@param [\"bert-base-uncased\", \"bert-large-uncased\", \"albert-base-v2\", \"roberta-base\", \"roberta-large\", \"distilbert-base-uncased\"]\n",
        "\n",
        "# The DataLoader needs to know our batch size for training. BERT Authors recommend 16 or 32, however this leads to an error due to not enough GPU memory\n",
        "BATCH_SIZE = 16 #@param [\"8\", \"16\", \"32\"] {type:\"raw\"}\n",
        "MAX_TOKEN_SIZE = 256 #@param [512,256,128] {type:\"raw\"}\n",
        "SHOW_GPU_USAGE = False #@param {type:\"boolean\"}\n",
        "\n",
        "# F1 evaluation metric config. See for context: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "F1_AVERAGING_STRATEGY = 'macro' #@param [\"micro\",  \"macro\", \"weighted\"]\n",
        "\n",
        "# To make the notebook reproducible (not guaranteed for pytorch on different releases/platforms!)\n",
        "SEED_VALUE = 0\n",
        "####################################################################\n",
        "\n",
        "model_id = TRANSFORMER_MODEL_NAME + \"_\" + CATEGORY_LEVEL\n",
        "print(f\"Selected {TRANSFORMER_MODEL_NAME} as transformer model for the task to classification of {CATEGORY_LEVEL}...\")\n",
        "\n",
        "# Initialize text wrapper\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Initialize random state\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)\n",
        "torch.cuda.manual_seed_all(SEED_VALUE)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Selected bert-base-uncased as transformer model for the task to classification of cro...\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PojOWgDxbCYT"
      },
      "source": [
        "## Data loading + preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0p6RB_hbWGg",
        "outputId": "56196f3d-c398-4595-af48-e231f60c2b5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load Google drive where the data and models are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Setup the models path\n",
        "saved_models_path = \"/content/drive/My Drive/fin-disclosures-nlp/models/finetuned_models/\"\n",
        "\n",
        "# Read training data\n",
        "df = pd.read_pickle(\"/content/drive/My Drive/fin-disclosures-nlp/data/labels/Firm_AnnualReport_Labels_100_combined.pkl\")\n",
        "\n",
        "# Drop n/a's:\n",
        "if CATEGORY_LEVEL == 'cro':\n",
        "  df.query('cro == [\"PR\", \"TR\", \"OP\"]', inplace=True)\n",
        "  no_of_categories = len(df.cro.unique())\n",
        "else:\n",
        "  df.query('cro_sub_type_combined.notnull() and cro_sub_type_combined != \"\"', inplace=True, engine='python')\n",
        "  no_of_categories = len(df.cro_sub_type_combined.unique())\n",
        "\n",
        "\n",
        "# Set texts and labels\n",
        "docs = df.text\n",
        "doc_labels = df[CATEGORY_LEVEL].astype('category').cat.codes.to_numpy(copy=True)\n",
        "\n",
        "# TODO: Load test data"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIoEbVpngkd6"
      },
      "source": [
        "## Data description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slNGVmIihT_p"
      },
      "source": [
        "### Class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XAvRbpEgAUk",
        "outputId": "eb60df12-728f-4109-dc50-c5fad3d7dad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Plot the number of labels of each category.\n",
        "sns.countplot(x=df[CATEGORY_LEVEL])\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel(f'{CATEGORY_LEVEL} Category')\n",
        "plt.ylabel('# of Samples')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of Samples')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oteGCQGFhbD0"
      },
      "source": [
        "### Document length\n",
        "\n",
        "Calculates the length of each document in terms of WordPiece tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_BSB7OHlnDI"
      },
      "source": [
        "# Load the tokenizer.\n",
        "expected_model_path = os.path.join(saved_models_path, model_id)\n",
        "has_model_path = os.path.isdir(expected_model_path)\n",
        "transformer_model_name = expected_model_path if has_model_path else TRANSFORMER_MODEL_NAME\n",
        "tokenizer = AutoTokenizer.from_pretrained(transformer_model_name, do_lower_case=True)\n",
        "\n",
        "def tokenize_and_count(row):\n",
        "  tokens = tokenizer.tokenize(row.text)\n",
        "  # Count unknown tokens --> TODO: Do they really exist with WordPiece?\n",
        "  unk_no = sum('[UNK]' in token for token in tokens)\n",
        "  # Count subwords from WordPiece segmentation\n",
        "  subwords_no = sum(token.startswith('##') for token in tokens)\n",
        "  # TODO: What's up with OOV (out of vocabulary?): They can't appear?\n",
        "  return pd.Series([len(tokens), unk_no, subwords_no])\n",
        "\n",
        "df[['token_no', 'unk_no', 'subwords_no' ]] = df.apply(lambda row: tokenize_and_count(row), axis=1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN-SIYC4qP-f",
        "outputId": "64651b05-9e9d-4fa3-8f7f-0b26df746c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Descriptive stats for number of tokens:\\n\", df.token_no.describe())\n",
        "print(\"==================\")\n",
        "print(\"Descriptive stats for WordPiece subwords (##...):\\n\", df.subwords_no.describe())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descriptive stats for number of tokens:\n",
            " count    917.00\n",
            "mean     101.47\n",
            "std       74.73\n",
            "min        5.00\n",
            "25%       53.00\n",
            "50%       87.00\n",
            "75%      127.00\n",
            "max      839.00\n",
            "Name: token_no, dtype: float64\n",
            "==================\n",
            "Descriptive stats for WordPiece subwords (##...):\n",
            " count    917.00\n",
            "mean       6.32\n",
            "std       11.45\n",
            "min        0.00\n",
            "25%        2.00\n",
            "50%        4.00\n",
            "75%        8.00\n",
            "max      207.00\n",
            "Name: subwords_no, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js-hIoBG0jBn",
        "outputId": "4540bf9c-3832-40d5-e6c5-7fb4235b00b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "# Truncate text lengths greater than 512.\n",
        "token_no = [min(l, 512) for l in df.token_no]\n",
        "token_no = df.token_no\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.displot(token_no, kde=False, rug=False)\n",
        "\n",
        "plt.title('Number of WordPiece tokens in Documents')\n",
        "plt.xlabel('WorkPiece Tokens')\n",
        "plt.ylabel('# of Documents')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(5.334999999999994, 0.5, '# of Documents')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMCl6ez57Hlt"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wA0M_b3wCx2"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx7jLyfr6Cr4"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def check_gpu_mem():\n",
        "    '''\n",
        "    Uses Nvidia's SMI tool to check the current GPU memory usage.\n",
        "    Reported values are in \"MiB\". 1 MiB = 2^20 bytes = 1,048,576 bytes.\n",
        "    '''\n",
        "    \n",
        "    # Run the command line tool and get the results.\n",
        "    buf = os.popen('nvidia-smi --query-gpu=memory.total,memory.used --format=csv')\n",
        "\n",
        "    # Use csv module to read and parse the result.\n",
        "    reader = csv.reader(buf, delimiter=',')\n",
        "\n",
        "    # Use a pandas table just for nice formatting.\n",
        "    df_gpu = pd.DataFrame(reader)\n",
        "\n",
        "    # Use the first row as the column headers.\n",
        "    new_header = df_gpu.iloc[0] #grab the first row for the header\n",
        "    df_gpu = df_gpu[1:] #take the data less the header row\n",
        "    df_gpu.columns = new_header #set the header row as the df header\n",
        "\n",
        "    return df_gpu"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCyx7wR86Z47"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxLHL-Ue5vCY"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voQxc_Af-Jrc"
      },
      "source": [
        "def multi_class_tokenize(docs, labels, max_len=512):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  for doc in docs:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            doc,                        # Doc to encode.\n",
        "                            add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
        "                            truncation = True,          # Activate truncation\n",
        "                            max_length = max_len,       # Truncate to length\n",
        "                            padding='max_length',       # Pad to max length \n",
        "                            return_attention_mask = True,   # Construct attn. masks\n",
        "                            return_tensors = 'pt',      # Return pytorch tensors\n",
        "                    )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  # Convert the labels to a tensor.\n",
        "  torch_labels = torch.tensor(labels).long()\n",
        "  # torch_labels = \n",
        "  \n",
        "  return (input_ids, torch_labels, attention_masks)\n",
        "\n",
        "\n",
        "# Tokenize the entire training dataset\n",
        "(train_input_ids, \n",
        " train_labels, \n",
        " train_attention_masks) = multi_class_tokenize(docs, doc_labels, max_len = MAX_TOKEN_SIZE)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk_NLz1x52dN"
      },
      "source": [
        "### Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DShtT9s7-rI"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "# Make sure that model dir exists if necessary\n",
        "if not ENABLE_FINE_TUNING:\n",
        "  assert expected_model_path\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    TRANSFORMER_MODEL_NAME if ENABLE_FINE_TUNING else expected_model_path, # Load fresh if fine tuning is enabled\n",
        "    num_labels = no_of_categories, # The number of different categories/labels\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "desc = model.cuda()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd0-tLiv8IRO",
        "outputId": "1a9b1a36-c1d4-4aa9-83d4-7da76f1a9b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        "        )\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  825 training samples\n",
            "   92 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92Heo-R8o-7"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phtxlas-8mtB"
      },
      "source": [
        "################ Training parameters ################\n",
        "epochs = 4 # Number of training epochs (BERT authors recommend between 2 and 4)\n",
        "lr = 2e-5\n",
        "eps = 1e-8\n",
        "max_grad_norm = 1.0\n",
        "num_warmup_steps = 0 # TODO: Try out 100?\n",
        "#####################################################\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = lr,eps = eps)\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer, \n",
        "      num_warmup_steps = num_warmup_steps, \n",
        "      num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "\n",
        "# Training stats will be stored here\n",
        "training_stats = []\n",
        "\n",
        "if ENABLE_FINE_TUNING:\n",
        "\n",
        "  # For each epoch...\n",
        "  for epoch_i in range(0, epochs):\n",
        "      \n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "      \n",
        "      # Perform one full pass over the training set.\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "\n",
        "      # Measure how long the training epoch takes.\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Reset the total loss for this epoch.\n",
        "      total_train_loss = 0\n",
        "\n",
        "      # Put the model into training mode. Don't be mislead--the call to \n",
        "      # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "      # `dropout` and `batchnorm` layers behave differently during training\n",
        "      # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "      model.train()\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "          # Progress update every 50 batches.\n",
        "          if step % 50 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "          # `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "\n",
        "          # Check GPU memory for the first couple steps.\n",
        "          if SHOW_GPU_USAGE and step < 2:\n",
        "              print('\\n  Step {:} GPU Memory Use:'.format(step))\n",
        "              df = check_gpu_mem()    \n",
        "              print('    Before forward-pass: {:}'.format(df.iloc[0, 1]))\n",
        "\n",
        "          # Always clear any previously calculated gradients before performing a\n",
        "          # backward pass. PyTorch doesn't do this automatically because \n",
        "          # accumulating the gradients is \"convenient while training RNNs\". \n",
        "          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "          model.zero_grad()        \n",
        "\n",
        "          # Perform a forward pass (evaluate the model on this training batch).\n",
        "          # The documentation for this `model` function is here: \n",
        "          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "          # It returns different numbers of parameters depending on what arguments\n",
        "          # arge given and what flags are set. For our useage here, it returns\n",
        "          # the loss (because we provided labels) and the \"logits\"--the model\n",
        "          # outputs prior to activation.\n",
        "          loss, logits = model(b_input_ids, \n",
        "                              token_type_ids=None, \n",
        "                              attention_mask=b_input_mask, \n",
        "                              labels=b_labels)\n",
        "\n",
        "          # Report GPU memory use for the first couple steps.\n",
        "          if SHOW_GPU_USAGE and  step < 2:\n",
        "              df = check_gpu_mem()    \n",
        "              print('     After forward-pass: {:}'.format(df.iloc[0, 1]))\n",
        "\n",
        "          # Accumulate the training loss over all of the batches so that we can\n",
        "          # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "          # single value; the `.item()` function just returns the Python value \n",
        "          # from the tensor.\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "          # Perform a backward pass to calculate the gradients.\n",
        "          loss.backward()\n",
        "\n",
        "          # Report GPU memory use for the first couple steps.\n",
        "          if SHOW_GPU_USAGE and step < 2:\n",
        "              df = check_gpu_mem()    \n",
        "              print('    After gradient calculation: {:}'.format(df.iloc[0, 1]))\n",
        "\n",
        "          # Clip the norm of the gradients to prevent the exploding gradient problem\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "          # Update parameters and take a step using the computed gradient.\n",
        "          # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "          # modified based on their gradients, the learning rate, etc.\n",
        "          optimizer.step()\n",
        "\n",
        "          # Update the learning rate.\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "      \n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epoch took: {:}\".format(training_time))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      # After the completion of each training epoch, measure our performance on\n",
        "      # our validation set.\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Put the model in evaluation mode--the dropout layers behave differently\n",
        "      # during evaluation.\n",
        "      model.eval()\n",
        "\n",
        "      # Tracking variables \n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      total_f1_score = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for batch in validation_dataloader:\n",
        "          \n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "          # the `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "          \n",
        "          # Tell pytorch not to bother with constructing the compute graph during\n",
        "          # the forward pass, since this is only needed for backprop (training).\n",
        "          with torch.no_grad():        \n",
        "\n",
        "              # Forward pass, calculate logit predictions.\n",
        "              # token_type_ids is the same as the \"segment ids\", which \n",
        "              # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "              # The documentation for this `model` function is here: \n",
        "              # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "              # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "              # values prior to applying an activation function like the softmax.\n",
        "              (loss, logits) = model(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels)\n",
        "              \n",
        "          # Accumulate the validation loss.\n",
        "          total_eval_loss += loss.item()\n",
        "\n",
        "          # Move logits and labels to CPU\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "          preds = np.argmax(logits, axis=1).flatten()\n",
        "          labels = label_ids.flatten()\n",
        "\n",
        "          # Calculate the accuracy for this batch of test sentences, and\n",
        "          # accumulate it over all batches.\n",
        "          total_eval_accuracy += accuracy_score(labels, preds, normalize=True)\n",
        "          total_f1_score += f1_score(labels, preds, average=F1_AVERAGING_STRATEGY)\n",
        "\n",
        "      # Report the final accuracy for this validation run.\n",
        "      avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "      print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      # Report the final F1 score for this validation run.\n",
        "      avg_f1_score =  total_f1_score / len(validation_dataloader)\n",
        "      print(\"  F1-Score: {0:.2f}\".format(avg_f1_score))\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "      \n",
        "      validation_time = format_time(time.time() - t0)\n",
        "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats.append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Valid. Accur.': avg_val_accuracy,\n",
        "              'Valid. F1': avg_f1_score,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "# Else load the model from storage\n",
        "else:\n",
        "  pass\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsDBME5n8z1y"
      },
      "source": [
        "## Check for overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hat-bEmU8yEZ",
        "outputId": "463580b8-e119-4e5d-cde4-48b48c988b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "if ENABLE_FINE_TUNING:\n",
        "  # Create a DataFrame from our training statistics.\n",
        "  df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "  # Use the 'epoch' as the row index.\n",
        "  df_stats = df_stats.set_index('epoch')\n",
        "  pd.set_option('precision', 2)\n",
        "  df_stats"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_xtUzAb84T_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "if ENABLE_FINE_TUNING:\n",
        "  # Use plot styling from seaborn.\n",
        "  sns.set(style='darkgrid')\n",
        "\n",
        "  # Increase the plot size and font size.\n",
        "  sns.set(font_scale=1.5)\n",
        "  plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "  # Plot the learning curve.\n",
        "  plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "  plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "  # Label the plot.\n",
        "  plt.title(\"Training & Validation loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.xticks(range(1,epochs + 1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ1nLPQM4EXX"
      },
      "source": [
        "# Evaluation on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjp9N4ydu2Fq"
      },
      "source": [
        "# TODO: For now, we use validation. Once test set is ready, switch...\n",
        "\n",
        "# Prepare the test dataset\n",
        "# (test_input_ids, test_labels, test_attention_masks) = multi_class_tokenize(docs_test, doc_test_labels, max_len = MAX_TOKEN_SIZE)\n",
        "test_data = val_dataset # TODO: replace with: TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=BATCH_SIZE)\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Measure elapsed time.\n",
        "t0 = time.time()\n",
        "\n",
        "# Predict \n",
        "for (step, batch) in enumerate(test_dataloader):\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "    # Telling the model not to compute or store the compute graph, saving memory\n",
        "    # and speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "# Combine the results across the batches.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Take the highest scoring output as the predicted label.\n",
        "predicted_labels = np.argmax(predictions, axis=1)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbyAu0l02mbt",
        "outputId": "c2d63dea-5053-4d8c-8bb5-48a46b4963b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate evaluation scores\n",
        "accuracy = accuracy_score(true_labels, predicted_labels, normalize=True)\n",
        "score = f1_score(true_labels, predicted_labels, average=F1_AVERAGING_STRATEGY)\n",
        "print('Accuracy: {:.3}'.format(accuracy))\n",
        "print('F1 score: {:.3}'.format(score))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.891\n",
            "F1 score: 0.819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IMSaown4Ew7",
        "outputId": "a24cd6ff-188b-4835-f94d-1c17dd9503f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix C, where C_{i,j} is equal to the number of observations known to be in group i and predicted to be in group j.\n",
        "# i = \n",
        "# From https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html:\n",
        "confusion_m = confusion_matrix(true_labels, predicted_labels)\n",
        "df_cm = pd.DataFrame(confusion_m, index = [c for c in df[CATEGORY_LEVEL].astype('category').cat.categories],\n",
        "                  columns = [c for c in df[CATEGORY_LEVEL].astype('category').cat.categories])\n",
        "plt.figure(figsize = (10,7))\n",
        "ax = sns.heatmap(df_cm, annot=True)\n",
        "ax.set(xlabel=\"Predicted (j)\", ylabel=\"Actual (i)\")\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(58.5, 0.5, 'Actual (i)'), Text(0.5, 31.5, 'Predicted (j)')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy7nfm3E4FwE"
      },
      "source": [
        "# Cleanup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1a1FLPZYV9j"
      },
      "source": [
        "## Store results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKt0WBWAYUI_",
        "outputId": "7e64a92c-77c7-4d07-f7b0-d9f8c534730c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "COLUMNS = [\"model_id\", \"transformer_model\", \"category_level\", \"accuracy\", \"f1_score\", \"f1_score_avg_strat\", \"confusion_matrix\"]\n",
        "RESULTS_FILE = \"/content/drive/My Drive/fin-disclosures-nlp/data/labels/Firm_AnnualReport_100_results.pkl\"\n",
        "\n",
        "try:\n",
        "  df_results = pd.read_pickle(RESULTS_FILE)\n",
        "except FileNotFoundError:\n",
        "  df_results = pd.DataFrame([], columns=COLUMNS)\n",
        "  df_results = df_results.set_index('model_id')\n",
        "  df_results.to_pickle(RESULTS_FILE)\n",
        "\n",
        "new_result = pd.DataFrame([[model_id, TRANSFORMER_MODEL_NAME, CATEGORY_LEVEL, accuracy, score, F1_AVERAGING_STRATEGY, df_cm]], columns=COLUMNS)\n",
        "new_result = new_result.set_index('model_id')\n",
        "\n",
        "df_results = pd.concat([df_results[~df_results.index.isin(new_result.index)], new_result])\n",
        "df_results.to_pickle(RESULTS_FILE)\n",
        "df_results"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>f1_score_avg_strat</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>transformer_model</th>\n",
              "      <th>category_level</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roberta-large_cro_sub_type_combined</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.71</td>\n",
              "      <td>macro</td>\n",
              "      <td>ACUTE  CHRON  MARKET  POLICY  PROD...</td>\n",
              "      <td>roberta-large</td>\n",
              "      <td>cro_sub_type_combined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roberta-large_cro</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.90</td>\n",
              "      <td>macro</td>\n",
              "      <td>OP  PR  TR\n",
              "OP  62   0   2\n",
              "PR   0  12   1\n",
              "T...</td>\n",
              "      <td>roberta-large</td>\n",
              "      <td>cro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bert-base-uncased_cro_sub_type_combined</th>\n",
              "      <td>0.77</td>\n",
              "      <td>0.45</td>\n",
              "      <td>macro</td>\n",
              "      <td>ACUTE  CHRON  MARKET  POLICY  PROD...</td>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>cro_sub_type_combined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bert-base-uncased_cro</th>\n",
              "      <td>0.89</td>\n",
              "      <td>0.82</td>\n",
              "      <td>macro</td>\n",
              "      <td>OP  PR  TR\n",
              "OP  61   0   2\n",
              "PR   1  11   1\n",
              "T...</td>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>cro</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         accuracy  ...         category_level\n",
              "model_id                                           ...                       \n",
              "roberta-large_cro_sub_type_combined          0.90  ...  cro_sub_type_combined\n",
              "roberta-large_cro                            0.93  ...                    cro\n",
              "bert-base-uncased_cro_sub_type_combined      0.77  ...  cro_sub_type_combined\n",
              "bert-base-uncased_cro                        0.89  ...                    cro\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78jUFiTPwIB"
      },
      "source": [
        "## Store to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRQO0u7OYsw6"
      },
      "source": [
        "if ENABLE_FINE_TUNING:\n",
        "  # Create temporary output dir\n",
        "  output_dir = f'./finetuned_models/{model_id}/'\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "  # Store model and tokenizer\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "  model_to_save.save_pretrained(output_dir)\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "  # Move to Google drive for persistance\n",
        "  os.makedirs(saved_models_path, exist_ok=True)\n",
        "  !cp -r $output_dir \"{drive_output_dir}\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}