{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import data.dataframe_preparation as preparation\n",
    "import data.utils.plotting as plotting\n",
    "\n",
    "# Make sure to reimport the local modules so changes in there are captured\n",
    "importlib.reload(preparation)\n",
    "importlib.reload(plotting)\n",
    "\n",
    "# Config\n",
    "OVERRIDE_RAW_OUTPUT = False\n",
    "OVERRIDE_TF_OUTPUT = True\n",
    "path = os.path.abspath(\"../input_files/all_files\")\n",
    "\n",
    "# Set up plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set() # rc={'figure.figsize':(8,6)})\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create raw file if not exits\n",
    "raw_file = Path(os.path.join(path, 'raw_dataset.csv'))\n",
    "if raw_file.is_file() and not OVERRIDE_RAW_OUTPUT:\n",
    "    raw_df = pd.read_csv(raw_file)\n",
    "else:\n",
    "    raw_df = preparation.get_df(input_path=path, report_type_mappings={\"CSR\": \"SR\"}, selected_report_types={\"AR\", \"SR\", \"20F\"}, include_page_no=False)\n",
    "    raw_df.to_csv(os.path.join(path, raw_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-f117ea976fb6>:26: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  norm_count_arr = count_matrix / df['total_word_count'][:, np.newaxis]\n",
      "/Users/david/Projects/fin-disclosures-nlp/envs/lib/python3.8/site-packages/scipy/sparse/base.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    }
   ],
   "source": [
    "# Load Term frequency file if exists\n",
    "tf_file = Path(os.path.join(path, 'tf_dataset.csv'))\n",
    "if tf_file.is_file() and not OVERRIDE_TF_OUTPUT:\n",
    "    df = pd.read_csv(tf_file)\n",
    "else:\n",
    "    # Prepare\n",
    "    df = raw_df\n",
    "    df['text'] = df['text'].fillna('Nothing')\n",
    "    \n",
    "    # Define vocabulary of interest for downstream calculations\n",
    "    # Note: Currently only supports Unigrams and bigrams. Would need to adapt 'ngram_range below'\n",
    "    vocabulary = ['climate change', 'global warming']\n",
    "\n",
    "    # Calculate total word count, ignoring punctuation\n",
    "    # total_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # df['total_word_count'] = df['text'].apply(lambda text: len(total_tokenizer.tokenize(text)))\n",
    "    df['total_word_count'] = df['text'].apply(lambda text: len(preparation.spacy_tokenizer(text)))\n",
    "    \n",
    "    # Calculate the term frequency of the selected tokens in the vocabulary\n",
    "    # count_vectorizer = CountVectorizer(ngram_range=(1,2), vocabulary=vocabulary, tokenizer=preparation.tokenize)\n",
    "    count_vectorizer = CountVectorizer(ngram_range=(1,2), vocabulary=vocabulary, tokenizer=preparation.spacy_tokenizer)\n",
    "    count_matrix = count_vectorizer.fit_transform(df['text'])\n",
    "    count_df = pd.DataFrame(count_matrix.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "    count_df = count_df.add_prefix('count_')\n",
    "    \n",
    "    norm_count_arr = count_matrix / df['total_word_count'][:, np.newaxis] \n",
    "    norm_count_df = pd.DataFrame(norm_count_arr, columns=count_vectorizer.get_feature_names())\n",
    "    norm_count_df = norm_count_df.add_prefix('norm_count_')\n",
    "    \n",
    "    # Calculate the normalized term frequency of the selected tokens in the vocabulary\n",
    "    # See here for reasoning: https://mail.python.org/pipermail/scikit-learn/2018-January/002174.html\n",
    "    # norm_count_vectorizer = TfidfVectorizer(use_idf=False, norm='l1', ngram_range=(1,2), vocabulary=vocabulary, tokenizer=preparation.tokenize)\n",
    "    # norm_count_vectorizer = TfidfVectorizer(use_idf=False, norm='l1', ngram_range=(1,2), tokenizer=preparation.spacy_tokenizer)\n",
    "    # norm_count_df = norm_count_vectorizer.fit_transform(df['text'])\n",
    "    # norm_count_df = pd.DataFrame(norm_count_df.toarray(), columns=norm_count_vectorizer.get_feature_names())\n",
    "    # norm_count_df = norm_count_df.add_prefix('norm_count_')\n",
    "    \n",
    "    # Calculate TF-IDF scores\n",
    "    # tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=preparation.tokenize,  strip_accents='ascii', vocabulary=vocabulary)\n",
    "    # tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=preparation.spacy_tokenizer,  strip_accents='ascii')\n",
    "    # tfidf_df = tf_idf_vectorizer.fit_transform(df['text'])\n",
    "    # tfidf_df = pd.DataFrame(tfidf_df.toarray(), columns=tf_idf_vectorizer.get_feature_names())\n",
    "    # tfidf_df = tfidf_df.add_prefix('tfidf_')\n",
    "    \n",
    "    # Sort and save\n",
    "    df = df.join(count_df).join(norm_count_df) # .join(tfidf_df)\n",
    "    df.sort_values(by=['company', 'report_type', 'year'])\n",
    "    df.to_csv(os.path.join(path, tf_file))\n",
    "\n",
    "filtered_reports = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 740    1999\n",
       "523    1999\n",
       "102    1999\n",
       "832    1999\n",
       "729    1999\n",
       "       ... \n",
       "310    2019\n",
       "313    2019\n",
       "810    2019\n",
       "561    2019\n",
       "537    2019\n",
       "Name: year, Length: 1430, dtype: int64>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reports = df[df['year'] > 2000]\n",
    "df.sort_values(by=\"year\").year.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use(\"pdf\")\n",
    "matplotlib.rcParams.update({\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        'font.family': 'serif',\n",
    "        'text.usetex': True,\n",
    "        'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "# Setup plot\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "\n",
    "\"\"\"\n",
    "report_type_total_chart = sns.lineplot(\n",
    "    ax=axs[0], \n",
    "    x=\"year\", \n",
    "    y=\"total_word_count\", \n",
    "    data=df, \n",
    "    hue=\"report_type\", \n",
    "    markers=True, \n",
    "    dashes=True,\n",
    ")\n",
    "report_type_total_chart.set(ylabel=\"Total number of words\", xlabel=\"Year\")\n",
    "for label in report_type_total_chart.xaxis.get_ticklabels()[::2]:\n",
    "    pass\n",
    "    # label.set_visible(False)\n",
    "\"\"\"\n",
    "category_column = \"report_type\"\n",
    "\n",
    "report_type_count_chart = sns.lineplot(ax=axs[0], x=\"year\", y=\"count_climate change\", data=filtered_reports, hue=category_column, markers=True, dashes=False)\n",
    "report_type_count_chart.set(ylabel=\"Term frequency of \\\\texttt{climate change}\", xlabel=\"Year\")\n",
    "\n",
    "report_type_norm_count_chart = sns.lineplot(ax=axs[1], x=\"year\", y=\"norm_count_climate change\", data=filtered_reports, hue=category_column, markers=True, dashes=False)\n",
    "report_type_norm_count_chart.set(ylabel=\"Normalized Term frequency\", xlabel=\"Year\")\n",
    "    \n",
    "# report_type_tfidf_chart = sns.lineplot(ax=axs[2], x=\"year\", y=\"tfidf_climate change\", data=df, hue=\"report_type\", markers=True, dashes=False)\n",
    "# for label in report_type_tfidf_chart.xaxis.get_ticklabels()[::2]:\n",
    "#     label.set_visible(False)\n",
    "  \n",
    "# Only add one legend\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "# Note there is a \"bug\" (or feature?) in seaborn, leading to always include the column name\n",
    "fig.legend(handles[1:], labels[1:], loc='upper center', ncol=4)\n",
    "report_type_count_chart.get_legend().remove()\n",
    "report_type_norm_count_chart.get_legend().remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "plotting.export_to_latex(fig, 'tf_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_chart = None;\n",
    "only_ar = filtered_reports[filtered_reports['report_type'].isin(['AR'])]\n",
    "country_chart = sns.lineplot(x=\"year\", y=\"norm_count_climate change\", data=only_ar, hue=\"country\", markers=True, dashes=False, ci=None, legend=\"brief\")\n",
    "for label in country_chart.xaxis.get_ticklabels()[::2]:\n",
    "    label.set_visible(False)\n",
    "country_chart.set(ylabel=\"Normalized Term frequency\", xlabel=\"Year\")\n",
    "  \n",
    "    \n",
    "plotting.export_to_latex(country_chart, 'ar_country_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = filtered_reports\n",
    "export_df = export_df.drop(columns=['text', 'toc'])\n",
    "export_df.to_csv('/Users/david/Projects/fin-disclosures-nlp/input_files/all_files/cc_count_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
